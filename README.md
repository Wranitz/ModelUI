# ModelUI
A simple flask UI that will run three model: llama Vison, LLama 3.2 3b and qwen 32b-coder using ollama.


# How to Run
1.Install Python3 and Ollama.

2.Install pip3.

3.Install all the dependencies.

4.In ollama download llama3.2:3b, llamavison, and qwen 2.5 coder

5.Run the Flask server

6.In your browser go to 127.0.0.1/5000.

7. You will see the app running.


# How to use
Before everything you need to be sure that you have all the dependencies as wella the Ollama models.After running the app:

1.Select the models you need to use.
2.Input the prompt on the webpage then Click submit.
3.You will see the answer on the right above a image after loading without the need to refresh dynamically.
